---
layout: archive
title: "CV"
permalink: /cv/
author_profile: true
redirect_from:
  - /resume
---

{% include base_path %}

Education
======
* Bachelor of Computer Science and Technology, University of Science and Technology of China (USTC), Sept. 2018 - June 2022
* Ph.D student at Institute of Computing Technology, Chinese Academy of Sciences, Sept. 2022 - present

Work experience
======
* Aug. 2021 - Jan. 2023 & Aug. 2023 - June 2025: Research intern
  * GenAI group, Microsoft Research Asia
  * Supervisor: Dr. [Furu Wei](https://thegenerality.com/) and [Shuming Ma](https://scholar.google.com/citations?user=J44tjDMAAAAJ)

* Feb. 2021 - July 2021: Teaching Assistant for Mathematical analysis B2, undergraduate course
  * USTC
  * Supervisor: Professor Yelong Zheng

* Sept. 2020 - Jan. 2021: Teaching Assistant for Mathematical analysis B1, undergraduate course
  * USTC
  * Supervisor: Professor Yelong Zheng

Awards
======
* Outstanding Teaching Assistant at USTC, 2021
* Silver Award of Outstanding Student Scholarship at USTC, 2020
* Huawei Scholarship, 2020
* Silver Award of Outstanding Student Scholarship at USTC, 2019

Services
======
* Journal Reviewer: IEEE Transactions on Affective Computing.
* Conference Reviewer: ICLR, ICCV, ECCV, EMNLP, ACL Rolling Review.

Talks
======
* (05/2024) The Era of 1-bit LLM (BitNet b1 / b1.58 / a4.8 / v2 ) at Xiaomi LLM-Core. [Slides](https://github.com/ustcwhy/ustcwhy.github.io/blob/master/files/bitnet-20250527.pdf).
* (08/2024) The Era of 1-bit LLM at [MSR Asia Intern Tech Fest](https://mp.weixin.qq.com/s/HVhOhWpq1092Z5byc5nISw).
* (06/2024) The Era of 1-bit LLM at [Cohere for AI](https://www.youtube.com/watch?v=oxQjGOUbQx4&list=PLLalUvky4CLJKDaiWCumhsJpHNDhZeVll&index=17&t=229s), and SIGMA Lab, Tsinghua University.
* (04/2024) BitNet b1.58 at MiraclePlus.
* (08/2023) Magneto at [Microsoft Research Asia](https://www.msra.cn/zh-cn/news/features/icml-2023).

Preprints & Publications
======
## Scalable and Efficient Foundation Model
* [MoTE: Mixture of Ternary Experts for Memory-efficient Large Multimodal Models.](https://ustcwhy.github.io/publications/mote) <b>Hongyu Wang</b>, Jiayu Xu, Ruiping Wang, Yan Feng, Yitao Zhai, Peng Pei, Xunliang Cai, Xilin Chen.
* [BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation.](https://ustcwhy.github.io/publications/bitvla) <b>Hongyu Wang</b>, Chuyan Xiong, Ruiping Wang, Xilin Chen.
* [BitNet v2: Native 4-bit Activations with Hadamard Transformation for 1-bit LLMs.](https://ustcwhy.github.io/publications/bitnet_v2/) <b>Hongyu Wang\*</b>, Shuming Ma\*, Furu Wei.
* [BitNet b1.58 2B4T Technical Report.](https://ustcwhy.github.io/publications/bitnet_2b4t/) Shuming Ma\*, <b>Hongyu Wang\*</b>, Shaohan Huang, Xingxing Zhang, Ying Hu, Ting Song, Yan Xia, Furu Wei
* [BitNet a4.8: 4-bit Activations for 1-bit LLMs.](https://ustcwhy.github.io/publications/bitnet_a4_8/) <b>Hongyu Wang\*</b>, Shuming Ma\*, Furu Wei.
* [Bitnet.cpp: Efficient Edge Inference for Ternary LLMs.](https://ustcwhy.github.io/publications/bitnet_cpp/) Jinheng Wang, Hansong Zhou, Ting Song, Shijie Cao, Yan Xia, Ting Cao, Jianyu Wei, Shuming Ma, <b>Hongyu Wang</b>, Furu Wei. ACL 2025.
* [Q-Sparse: All Large Language Models can be Fully Sparsely-Activated.](https://ustcwhy.github.io/publications/qsparse/) <b>Hongyu Wang\*</b>, Shuming Ma\*, Ruiping Wang, Furu Wei.
* [DeepNet: Scaling Transformers to 1,000 Layers.](https://ustcwhy.github.io/publications/deepnet/) <b>Hongyu Wang\*</b>, Shuming Ma\*, Li Dong, Shaohan Huang, Dongdong Zhang, Furu Wei, IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI 2024).
* [The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits.](https://ustcwhy.github.io/publications/bitnet_b1_58) Shuming Ma\*, <b>Hongyu Wang\*</b>, Lingxiao Ma, Lei Wang, Wenhui Wang, Shaohan Huang, Li Dong, Ruiping Wang, Jilong Xue, Furu Wei.
* [BitNet: Scaling 1-bit Transformers for Large Language Models.](https://ustcwhy.github.io/publications/bitnet) <b>Hongyu Wang\*</b>, Shuming Ma\*, Li Dong, Shaohan Huang, Huaijie Wang, Lingxiao Ma, Fan Yang, Ruiping Wang, Yi Wu, Furu Wei.
* [Magneto: A Foundation Transformer.](https://ustcwhy.github.io/publications/foundation_transformer/) <b>Hongyu Wang\*</b>, Shuming Ma\*, Shaohan Huang, Li Dong, Wenhui Wang, Zhiliang Peng, Yu Wu, Payal Bajaj, Saksham Singhal, Alon Benhaim, Barun Patra, Zhun Liu, Vishrav Chaudhary, Xia Song, Furu Wei. International Conference on Machine Learning (ICML), 2023.
* [TorchScale: Transformers at Scale.](https://ustcwhy.github.io/publications/torchscale/) Shuming Ma\*, <b>Hongyu Wang\*</b>, Shaohan Huang, Wenhui Wang, Zewen Chi, Li Dong, Alon Benhaim, Barun Patra, Vishrav Chaudhary, Xia Song, Furu Wei.

## Multimodal and Robotics
* [M4U: Evaluating Multilingual Understanding and Reasoning for Large Multimodal Models.](https://ustcwhy.github.io/publications/m4u/) <b>Hongyu Wang\*</b>, Jiayu Xu\*, Senwei Xie\*, Ruiping Wang, Jialin Li, Zhaojie Xie, Bin Zhang, Chuyan Xiong, Xilin Chen.
* [Robotic Programmer: Video Instructed Policy Code Generation for Robotic Manipulation.](https://ustcwhy.github.io/publications/robopro/) Senwei Xie\*, <b>Hongyu Wang\*</b>, Zhanqi Xiao\*, Ruiping Wang, Xilin Chen. IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2025.


Media Reports
======
* **BitNet v2**: [AI era (Chinese)](https://mp.weixin.qq.com/s/CafL3szFrBMuISRG0GUpWQ), [QbitAI (Chinese)](https://mp.weixin.qq.com/s/HlSDd3Tl5lK4sHSm25z9XQ)
* **BitNet b1.58 2B4T**: [TechCrunch](https://techcrunch.com/2025/04/16/microsoft-researchers-say-theyve-developed-a-hyper-efficient-ai-model-that-can-run-on-cpus/), [Microsoft Fiscal Year 2025 Third Quarter Earnings Conference Call](https://www.microsoft.com/en-us/investor/events/fy-2025/earnings-fy-2025-q3), [AI era (Chinese)](https://mp.weixin.qq.com/s/G9ZbMnBVbeH1m45HY2JIKA), [QbitAI (Chinese)](https://mp.weixin.qq.com/s/CpHcrSpzoDYcagknX9oe5g)
* **BitNet a4.8**: [VentureBeat](https://venturebeat.com/ai/how-microsofts-next-gen-bitnet-architecture-is-turbocharging-llm-efficiency/), [AI era (Chinese)](https://mp.weixin.qq.com/s/aw3iXwNVypyrq7jnAgGoug)
* **BitNet.cpp**: [QbitAI (Chinese)](https://mp.weixin.qq.com/s/gerCRxj4eULOut9PtMlNog)
* **Q-Sparse**: [Microsoft Research (Chinese)](https://mp.weixin.qq.com/s/JlvfBXLgn_aS9GrhhAYncQ), [QbitAI (Chinese)](https://mp.weixin.qq.com/s/hBC9TcYrHMGVG9VgogLqWw)
* **BitNet b1.58**: [IEEE Spectrum](https://spectrum.ieee.org/1-bit-llm), [Forbes](https://www.forbes.com/sites/lanceeliot/2024/11/22/small-bits-big-ideas-the-amazing-rise-of-1-bit-llms-for-building-faster-and-slimer-generative-ai-apps/), [QbitAI (Chinese)](https://mp.weixin.qq.com/s/ziQDq8eaFCKlMaMKV9EM8Q), [Synced (Chinese)](https://mp.weixin.qq.com/s/ao71aBUsEXoO_DC3hwpqQA), [Microsoft Research (Chinese)](https://mp.weixin.qq.com/s/4qtD_S_cC8OF0GENBPP-_Q), [xTech (Japanese)](https://xtech.nikkei.com/atcl/nxt/column/18/00001/10028/)
* **TorchScale**: [Microsoft Research (Chinese)](https://mp.weixin.qq.com/s/7oSv-RlwpWRPy5-t8meKCA)
* **DeepNet**: [QbitAI (Chinese)](https://mp.weixin.qq.com/s/3cN5I1hqPZNe6cXUPJ2wVA), [Synced (Chinese)](https://mp.weixin.qq.com/s/ejXE4-oBkqqtYITKZHpudQ), [AI era (Chinese)](https://mp.weixin.qq.com/s/Vo-mlDMjYQXmwAsXkhF3Yg)

  
<!-- Talks
======
  <ul>{% for post in site.talks %}
    {% include archive-single-talk-cv.html %}
  {% endfor %}</ul>
  
Teaching
======
  <ul>{% for post in site.teaching %}
    {% include archive-single-cv.html %}
  {% endfor %}</ul>
  
Service and leadership
======
* Currently signed in to 43 different slack teams -->
